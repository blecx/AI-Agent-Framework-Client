name: Client CI

on:
  push:
    branches: [main]
  pull_request:

jobs:
  changes:
    name: Detect changed paths
    runs-on: ubuntu-latest
    outputs:
      api_integration: ${{ steps.filter.outputs.api_integration }}
    steps:
      - uses: actions/checkout@v4
      - name: Path filter
        id: filter
        uses: dorny/paths-filter@v3
        with:
          filters: |
            api_integration:
              - 'client/src/**'
              - 'client/scripts/**'
              - 'client/package.json'
              - 'client/package-lock.json'
              - '.github/workflows/ci.yml'

  client-ci:
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v4

      - name: PR review gate (goal + acceptance criteria + validation)
        if: ${{ github.event_name == 'pull_request' }}
        uses: actions/github-script@v7
        with:
          script: |
            const pr = context.payload.pull_request;
            if (!pr) {
              core.info('No pull_request payload found; skipping.');
              return;
            }

            const body = pr.body || '';
            const requiredMarkers = [
              '# Summary',
              '## Goal / Acceptance Criteria (required)',
              '## Issue / Tracking Link (required)',
              '## Validation (required)',
              '## Automated checks',
              '## Manual test evidence (required)',
              '## Cross-repo / Downstream impact (always include)',
            ];
            const missing = requiredMarkers.filter(m => !body.includes(m));
            if (missing.length) {
              core.setFailed(`PR description is missing required sections: ${missing.join(', ')}`);
              return;
            }

            function sectionText(md, heading) {
              const start = md.indexOf(heading);
              if (start === -1) return '';
              const rest = md.slice(start + heading.length);
              const next = rest.search(/\n#{1,2}\s+/);
              return (next === -1 ? rest : rest.slice(0, next)).trim();
            }

            function checkboxLines(mdSection) {
              return mdSection
                .split(/\r?\n/)
                .map(l => l.trim())
                .filter(l => /^- \[[ xX]\]/.test(l));
            }

            function requireCheckboxChecked(section, pattern, label) {
              const lines = section.split(/\r?\n/).map(l => l.trim());
              const line = lines.find(l => pattern.test(l));
              if (!line) return `Missing checkbox line for: ${label}`;
              if (!/^\- \[[xX]\]/.test(line)) return `Checkbox must be checked for: ${label}`;
              return null;
            }

            // Acceptance criteria must exist and be checked
            const ac = sectionText(body, '## Goal / Acceptance Criteria (required)');
            const acBoxes = checkboxLines(ac);
            const problems = [];
            if (acBoxes.length === 0) problems.push('Acceptance Criteria section must include at least one checkbox item.');
            if (acBoxes.length && acBoxes.some(l => !/^\- \[[xX]\]/.test(l))) problems.push('All Acceptance Criteria checkboxes must be checked.');

            // Tracking link must not be placeholder underscores
            const fixesLine = (body.split(/\r?\n/).find(l => l.trim().toLowerCase().startsWith('fixes:')) || '').trim();
            const fixesValue = fixesLine.replace(/^fixes:\s*/i, '').trim();
            const fixesOk =
              fixesValue.length > 0 &&
              !/_{5,}/.test(fixesValue) &&
              !/\*{3,}/.test(fixesValue) &&
              (['none', 'n/a', 'na'].includes(fixesValue.toLowerCase()) || /#\d+/.test(fixesValue) || /https?:\/\//.test(fixesValue));
            if (!fixesOk) problems.push('Fixes: must reference a real issue/ticket (e.g. Fixes #123 or URL) or be explicitly "None"/"N/A".');

            // Validation checkboxes
            const auto = sectionText(body, '## Automated checks');
            const manual = sectionText(body, '## Manual test evidence (required)');

            const lintReq = requireCheckboxChecked(auto, /^- \[[ xX]\]\s+Lint passes\b/, 'Lint passes');
            if (lintReq) problems.push(lintReq);
            const buildReq = requireCheckboxChecked(auto, /^- \[[ xX]\]\s+Build passes\b/, 'Build passes');
            if (buildReq) problems.push(buildReq);
            const manualReq = requireCheckboxChecked(manual, /^- \[[ xX]\]\s+Manual test entry #1\b/, 'Manual test entry #1');
            if (manualReq) problems.push(manualReq);

            function hasNonPlaceholderValue(line) {
              const value = (line || '').split(':').slice(1).join(':').trim();
              if (!value) return false;
              if (/_{5,}/.test(value)) return false;
              if (/\*{3,}/.test(value)) return false;
              if (/^\*+$/.test(value)) return false;
              return true;
            }

            function findBlockDetails(lines, checkboxRegex) {
              const idx = lines.findIndex(l => checkboxRegex.test(l));
              if (idx === -1) return { command: '', evidence: '' };
              const window = lines.slice(idx, idx + 12);
              const command = window.find(l => l.startsWith('- Command(s):')) || '';
              const evidence = window.find(l => l.toLowerCase().startsWith('- evidence')) || '';
              return { command, evidence };
            }

            // Require at least one meaningful "How to review" step
            const howToReview = sectionText(body, '## How to review');
            const reviewSteps = howToReview
              .split(/\r?\n/)
              .map(l => l.trim())
              .filter(l => /^\d+\./.test(l));
            const meaningfulSteps = reviewSteps.filter(l => !/^\d+\.\s*$/.test(l));
            if (meaningfulSteps.length === 0) {
              problems.push('How to review must include at least one numbered step with content.');
            }

            // Require non-placeholder commands/evidence for lint/build
            const autoLines = auto.split(/\r?\n/).map(l => l.trim()).filter(Boolean);
            const lintDetails = findBlockDetails(autoLines, /^- \[[ xX]\]\s+Lint passes\b/i);
            if (lintDetails.command && !hasNonPlaceholderValue(lintDetails.command)) problems.push('Lint passes: Command(s) must be filled (not placeholder).');
            if (lintDetails.evidence && !hasNonPlaceholderValue(lintDetails.evidence)) problems.push('Lint passes: Evidence must be filled (not placeholder).');

            const buildDetails = findBlockDetails(autoLines, /^- \[[ xX]\]\s+Build passes\b/i);
            if (buildDetails.command && !hasNonPlaceholderValue(buildDetails.command)) problems.push('Build passes: Command(s) must be filled (not placeholder).');
            if (buildDetails.evidence && !hasNonPlaceholderValue(buildDetails.evidence)) problems.push('Build passes: Evidence must be filled (not placeholder).');

            // Manual test entry details must not be placeholders
            const manualLines = manual.split(/\r?\n/).map(l => l.trim());
            const scenarioLine = manualLines.find(l => l.startsWith('- Scenario:'));
            const expectedLine = manualLines.find(l => l.startsWith('- Expected result:'));
            const actualLine = manualLines.find(l => l.startsWith('- Actual result / Evidence'));
            if (scenarioLine && !hasNonPlaceholderValue(scenarioLine)) problems.push('Manual test entry #1: Scenario must be filled (not placeholder).');
            if (expectedLine && !hasNonPlaceholderValue(expectedLine)) problems.push('Manual test entry #1: Expected result must be filled (not placeholder).');
            if (actualLine && !hasNonPlaceholderValue(actualLine)) problems.push('Manual test entry #1: Actual result / Evidence must be filled (not placeholder).');

            // Cross-repo impact must be explicitly filled (can be "None")
            const crossRepoLine = (body.split(/\r?\n/).find(l => l.trim().startsWith('- Related repos/services impacted:')) || '').trim();
            if (!crossRepoLine || /_{5,}/.test(crossRepoLine)) {
              problems.push('Cross-repo impact must be filled (use "None" if not applicable).');
            }

            // Lightweight implementation guard: require test changes when UI code changes.
            const files = await github.paginate(github.rest.pulls.listFiles, {
              owner: context.repo.owner,
              repo: context.repo.repo,
              pull_number: pr.number,
              per_page: 100,
            });
            const changed = files.map(f => f.filename);
            const uiTouched = changed.some(p => p.startsWith('client/src/'));
            const scriptsTouched = changed.some(p => p.startsWith('client/scripts/'));
            const testsTouched = changed.some(p => /client\/(src\/.*\.(test|spec)\.[jt]sx?$|e2e\/|__tests__\/|playwright\.config\.|vitest\.config\.)/.test(p));
            if (uiTouched && !testsTouched) {
              problems.push('UI code changed under client/src/ but no client tests were updated/added (unit or e2e).');
            }
            if (scriptsTouched && !testsTouched) {
              problems.push('Client scripts changed under client/scripts/ but no tests were updated/added (unit or e2e).');
            }

            if (problems.length) {
              core.setFailed(`PR review gate failed:\n- ${problems.join('\n- ')}`);
              return;
            }
            core.info('PR review gate passed.');

      - name: Repo hygiene guard (forbidden env files)
        shell: bash
        run: |
          set -euo pipefail
          # Forbid committing real env files; examples are allowed.
          if git ls-files | grep -E '(^|/)\.env$|(^|/)\.env\.local$|(^|/)\.env\.production$|(^|/)\.env\.e2e$' -n; then
            echo "Forbidden env files detected in git index (.env/.env.local/.env.production/.env.e2e)."
            echo "Use .env.example files instead."
            exit 1
          fi

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: 'client/package-lock.json'

      - name: Install dependencies
        working-directory: client
        run: npm ci

      - name: Run lint
        working-directory: client
        run: npm run lint

      - name: Run tests with coverage
        working-directory: client
        run: npm run test:coverage

      - name: Check coverage thresholds
        working-directory: client
        run: |
          echo "ğŸ“Š Coverage report generated"
          if [ -f coverage/coverage-summary.json ]; then
            echo "Coverage summary:"
            cat coverage/coverage-summary.json | jq '.total'
          fi

      - name: Upload coverage reports
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: coverage-report
          path: client/coverage/
          retention-days: 30

      - name: Build
        working-directory: client
        run: npm run build

      - name: Check bundle size
        working-directory: client
        run: |
          set -euo pipefail
          echo "Checking bundle size limits..."
          
          # Find the main JS bundle
          MAIN_JS=$(find dist/assets -name 'index-*.js' | head -n 1)
          
          if [ -z "$MAIN_JS" ]; then
            echo "Error: Could not find main bundle"
            exit 1
          fi
          
          # Get gzipped size
          GZIP_SIZE=$(gzip -c "$MAIN_JS" | wc -c)
          GZIP_SIZE_KB=$((GZIP_SIZE / 1024))
          MAX_SIZE_KB=500
          
          echo "Main bundle: $(basename "$MAIN_JS")"
          echo "Gzipped size: ${GZIP_SIZE_KB} KB"
          echo "Limit: ${MAX_SIZE_KB} KB"
          
          if [ "$GZIP_SIZE_KB" -gt "$MAX_SIZE_KB" ]; then
            echo "âŒ Bundle size exceeds limit!"
            echo "   Current: ${GZIP_SIZE_KB} KB"
            echo "   Maximum: ${MAX_SIZE_KB} KB"
            exit 1
          fi
          
          echo "âœ… Bundle size check passed (${GZIP_SIZE_KB} KB < ${MAX_SIZE_KB} KB)"

      - name: Check production build for console errors
        working-directory: client
        run: |
          set -euo pipefail
          echo "Checking production build for console.error/console.warn..."
          
          # Search for console.error and console.warn in built files
          if grep -rn "console\.\(error\|warn\)" dist/assets/*.js 2>/dev/null; then
            echo "âŒ Found console.error or console.warn in production build"
            echo "   Remove or guard console statements for production"
            exit 1
          fi
          
          echo "âœ… No console errors/warnings in production build"

      - name: Check bundle size
        working-directory: client
        run: npm run check:bundle-size

      - name: Check for console errors in build
        working-directory: client
        run: |
          echo "ğŸ” Checking for console errors in production build..."
          if grep -r "console\.\(log\|error\|warn\|debug\)" dist/ --include="*.js" 2>/dev/null; then
            echo "âš ï¸  Warning: Console statements found in production build"
            echo "Consider removing console statements or using a build plugin to strip them"
            # This is a warning, not a failure for now
          else
            echo "âœ… No console errors found in production build"
          fi

      - name: Validate documentation
        working-directory: client
        run: npm run check:docs

      - name: Run tests with coverage
        working-directory: client
        run: npm test -- --coverage

      - name: Check test coverage thresholds
        working-directory: client
        run: |
          echo "Coverage thresholds: 80% for lines, functions, branches, statements"
          echo "Configured in vitest.config.ts"

  api-integration:
    needs: [changes, client-ci]
    if: ${{ github.ref == 'refs/heads/main' || needs.changes.outputs.api_integration == 'true' }}
    uses: blecx/AI-Agent-Framework/.github/workflows/reusable-client-api-integration.yml@main
    with:
      client_runtime: node
      node_version: '20'
      client_workdir: client
      client_install_command: npm ci
      client_lint_command: ''
      client_build_command: ''
      client_test_command: npm run test:api

  # E2E tests with smart dependency resolution
  # This job implements intelligent backend dependency resolution:
  # 1. Attempts to resolve all dependencies automatically
  # 2. Only skips tests if dependencies are truly unresolvable
  # 3. Logs detailed reasons for any skipped tests
  # For details, see docs/E2E-CI-DEPENDENCY-RESOLUTION.md
  client-e2e:
    runs-on: ubuntu-latest
    needs: client-ci
    # Run on main branch or when 'run-e2e' label is present
    if: github.ref == 'refs/heads/main' || contains(github.event.pull_request.labels.*.name, 'run-e2e')

    steps:
      - name: Checkout client repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: 'client/package-lock.json'

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install client dependencies
        working-directory: client
        run: npm ci

      - name: Install Playwright browsers
        working-directory: client
        run: npx playwright install --with-deps chromium

      - name: Attempt backend dependency resolution
        id: backend_setup
        # Note: continue-on-error is INTENTIONAL for two-run strategy
        # First run: Attempt resolution and set output variable
        # Second run: Check output variable and skip if failed
        # This allows us to capture logs and display clear skip messages
        continue-on-error: true
        run: |
          echo "=== Smart Backend Dependency Resolution ==="
          echo "Starting dependency resolution process..."
          echo ""

          # Set backend directory in CI environment
          export BACKEND_DIR="${GITHUB_WORKSPACE}/../AI-Agent-Framework"
          export LOG_FILE="${GITHUB_WORKSPACE}/backend-setup.log"

          # Run the smart setup script
          if bash client/e2e/setup-backend.sh; then
            echo "backend_available=true" >> $GITHUB_OUTPUT
            echo ""
            echo "âœ“ Backend setup successful"
          else
            echo "backend_available=false" >> $GITHUB_OUTPUT
            echo ""
            echo "âœ— Backend setup failed"
            echo "See backend-setup.log for details"
          fi

      - name: Display backend setup log
        if: always()
        run: |
          if [ -f backend-setup.log ]; then
            echo "=== Backend Setup Log ==="
            cat backend-setup.log
          fi

      - name: Run E2E tests
        if: steps.backend_setup.outputs.backend_available == 'true'
        working-directory: client
        run: npx playwright test
        env:
          E2E_BASE_URL: http://localhost:5173
          API_BASE_URL: http://localhost:8000

      - name: Skip E2E tests with reason
        if: steps.backend_setup.outputs.backend_available != 'true'
        run: |
          echo ""
          echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
          echo "E2E TESTS SKIPPED - DEPENDENCY RESOLUTION FAILED"
          echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
          echo ""
          echo "The E2E tests were skipped because backend dependencies"
          echo "could not be resolved automatically."
          echo ""
          echo "ATTEMPTED RESOLUTION METHODS:"
          echo "  1. Clone backend repository from GitHub"
          echo "  2. Start backend via Docker Compose"
          echo "  3. Create Python venv and install dependencies"
          echo "  4. Start backend via uvicorn"
          echo ""
          echo "All methods failed. See backend-setup.log artifact for details."
          echo ""
          echo "TO FIX:"
          echo "  - Ensure backend repository is accessible"
          echo "  - Verify backend has requirements.txt or docker-compose.yml"
          echo "  - Check backend health endpoint works"
          echo ""
          echo "For more information:"
          echo "  - docs/E2E-CI-DEPENDENCY-RESOLUTION.md"
          echo "  - docs/E2E-CI-SETUP.md"
          echo ""
          echo "E2E tests will run successfully once dependencies are resolved."
          echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

      - name: Upload backend setup log
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: backend-setup-log
          path: backend-setup.log
          if-no-files-found: ignore

      - name: Upload Playwright report
        if: always() && steps.backend_setup.outputs.backend_available == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: playwright-report
          path: client/playwright-report/
          retention-days: 30

      - name: Upload test screenshots
        if: failure() && steps.backend_setup.outputs.backend_available == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: test-screenshots
          path: client/test-results/
          retention-days: 30

      - name: Upload backend logs
        if: always() && steps.backend_setup.outputs.backend_available == 'true'
        uses: actions/upload-artifact@v4
        with:
          name: backend-logs
          path: /tmp/backend-e2e.log
          if-no-files-found: ignore

  # Lighthouse CI for performance and accessibility testing
  # Runs on main branch or when 'run-lighthouse' label is present
  lighthouse:
    runs-on: ubuntu-latest
    needs: client-ci
    # Run on main branch or when 'run-lighthouse' label is present
    if: github.ref == 'refs/heads/main' || contains(github.event.pull_request.labels.*.name, 'run-lighthouse')

    steps:
      - name: Checkout client repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
          cache: 'npm'
          cache-dependency-path: 'client/package-lock.json'

      - name: Install dependencies
        working-directory: client
        run: npm ci

      - name: Build for Lighthouse
        working-directory: client
        run: npm run build

      - name: Start preview server
        working-directory: client
        run: |
          npm run preview &
          echo $! > preview.pid
          sleep 5
          curl http://localhost:5173 || echo "Preview server not ready yet"

      - name: Run Lighthouse CI
        working-directory: client
        run: |
          npm run lighthouse:ci || {
            echo ""
            echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
            echo "LIGHTHOUSE CI FAILED"
            echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
            echo ""
            echo "One or more Lighthouse thresholds were not met:"
            echo "  - Performance: Minimum 80"
            echo "  - Accessibility: Minimum 90"
            echo "  - Best Practices: Minimum 80"
            echo ""
            echo "ğŸ’¡ REMEDIATION STEPS:"
            echo ""
            echo "Performance (< 80):"
            echo "  1. Optimize images (use WebP, lazy loading)"
            echo "  2. Reduce JavaScript bundle size"
            echo "  3. Implement code splitting"
            echo "  4. Use CDN for static assets"
            echo "  5. Enable compression (gzip/brotli)"
            echo ""
            echo "Accessibility (< 90):"
            echo "  1. Add ARIA labels to interactive elements"
            echo "  2. Ensure sufficient color contrast"
            echo "  3. Add alt text to images"
            echo "  4. Ensure keyboard navigation works"
            echo "  5. Fix any axe-core violations"
            echo ""
            echo "Best Practices (< 80):"
            echo "  1. Fix browser console errors"
            echo "  2. Use HTTPS in production"
            echo "  3. Avoid deprecated APIs"
            echo "  4. Fix security vulnerabilities"
            echo ""
            echo "View detailed report in Lighthouse CI artifacts"
            echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
            exit 1
          }

      - name: Stop preview server
        if: always()
        working-directory: client
        run: |
          if [ -f preview.pid ]; then
            kill $(cat preview.pid) || true
            rm preview.pid
          fi

      - name: Upload Lighthouse report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: lighthouse-report
          path: client/.lighthouseci/
          retention-days: 30
