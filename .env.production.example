# Production Environment Configuration for AI Agent Framework Full Stack
# ==============================================================================
# This file contains environment variables for production deployment of both
# the Client and API services.
# ==============================================================================

# ==============================================================================
# API Configuration
# ==============================================================================

# Port for the API service
API_PORT=8000

# Host for the API to bind to (0.0.0.0 for all interfaces)
API_HOST=0.0.0.0

# ==============================================================================
# Client Configuration
# ==============================================================================

# Port for the client service (maps to internal port 80 in Docker)
CLIENT_PORT=3000

# API URL for the client to connect to
# For Docker internal networking (recommended):
VITE_API_BASE_URL=http://ai-agent-api:8000/api

# For external/public API:
# VITE_API_BASE_URL=https://api.yourdomain.com/api

# ==============================================================================
# LLM Configuration
# ==============================================================================

# LLM Provider (lm-studio, openai, anthropic, azure, custom)
LLM_PROVIDER=lm-studio

# LLM API URL
LLM_API_URL=http://localhost:1234/v1

# LLM Model name
LLM_MODEL=local-model

# LLM Temperature (0.0-1.0)
LLM_TEMPERATURE=0.7

# LLM Max tokens
LLM_MAX_TOKENS=2000

# ==============================================================================
# File Paths
# ==============================================================================

# Path for project documents (API)
PROJECT_DOCS_PATH=./projectDocs

# Path for LLM configuration file (API)
LLM_CONFIG_PATH=./config/llm.json

# ==============================================================================
# Security Configuration
# ==============================================================================

# API Key for authentication (generate a secure random key)
# Example: openssl rand -hex 32
# API_KEY=your-secure-api-key-here

# Allowed CORS origins (comma-separated)
# ALLOWED_ORIGINS=https://yourdomain.com,https://www.yourdomain.com

# ==============================================================================
# Logging Configuration
# ==============================================================================

# Log level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOG_LEVEL=INFO

# ==============================================================================
# Database Configuration (if applicable)
# ==============================================================================

# Database URL (if using a database)
# DATABASE_URL=postgresql://user:password@localhost:5432/dbname

# ==============================================================================
# External Services (optional)
# ==============================================================================

# Redis URL (if using Redis for caching)
# REDIS_URL=redis://localhost:6379

# Monitoring/Analytics (if applicable)
# SENTRY_DSN=
# ANALYTICS_ID=

# ==============================================================================
# Docker Configuration
# ==============================================================================

# Docker network name
DOCKER_NETWORK=ai-agent-network

# Container names
API_CONTAINER_NAME=ai-agent-api
CLIENT_CONTAINER_NAME=ai-agent-client

# ==============================================================================
# Important Notes for Production
# ==============================================================================

# 1. NEVER commit this file with real secrets to version control
# 2. Copy this file to .env.production and customize:
#    cp .env.production.example .env.production
# 3. Generate secure random keys for API_KEY:
#    openssl rand -hex 32
# 4. Use HTTPS in production with proper SSL certificates
# 5. Configure firewall to only allow necessary ports
# 6. Set up monitoring and log aggregation
# 7. Implement regular backups
# 8. Keep Docker images and dependencies updated
# 9. Use Docker secrets for sensitive data in production
# 10. Configure resource limits in docker-compose.production.yml

# ==============================================================================
# Environment-Specific Configurations
# ==============================================================================

# Development
# - Use localhost URLs
# - Enable debug logging
# - Disable authentication for testing

# Staging
# - Use staging API URL
# - Enable verbose logging
# - Use test credentials

# Production
# - Use production API URL with HTTPS
# - Set LOG_LEVEL=INFO or WARNING
# - Use strong authentication
# - Enable monitoring and alerting
# - Configure proper CORS origins
# - Use managed services for databases

# ==============================================================================
# Usage
# ==============================================================================

# This file is used by:
# 1. docker-compose.production.yml
# 2. Production setup scripts (production-setup.sh, production-setup.ps1)
# 3. Deployment automation

# To use:
# 1. Copy to .env.production: cp .env.production.example .env.production
# 2. Edit .env.production with your values
# 3. Source the file or let Docker Compose load it automatically
# 4. Deploy with: docker compose -f docker-compose.production.yml up -d
